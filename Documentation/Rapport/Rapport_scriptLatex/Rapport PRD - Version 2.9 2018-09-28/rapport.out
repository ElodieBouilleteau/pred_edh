\BOOKMARK [0][]{chapter*.3}{Pr\351ambule}{}% 1
\BOOKMARK [0][]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{Pr\351sentation de la probl\351matique}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Contexte}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.3}{Objectifs poursuivis}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.4}{Travail r\351alis\351}{chapter.1}% 6
\BOOKMARK [1][-]{section.1.5}{Contribution}{chapter.1}% 7
\BOOKMARK [1][-]{section.1.6}{Plan de l'\351tude}{chapter.1}% 8
\BOOKMARK [0][]{chapter.2}{\311tat de l'art}{}% 9
\BOOKMARK [1][-]{section.2.1}{Crit\350res d'\351valuation}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.2}{Proposition 1 : SORT avec une m\351trique d'association en profondeur}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.2.1}{Pr\351sentation}{section.2.2}% 12
\BOOKMARK [2][-]{subsection.2.2.2}{Analyse}{section.2.2}% 13
\BOOKMARK [1][-]{section.2.3}{Proposition 2 : Suivi de multiple objets en temps r\351el C++SORT}{chapter.2}% 14
\BOOKMARK [2][-]{subsection.2.3.1}{Pr\351sentation}{section.2.3}% 15
\BOOKMARK [2][-]{subsection.2.3.2}{Analyse}{section.2.3}% 16
\BOOKMARK [1][-]{section.2.4}{Proposition 3 : Ensemble de filtres de corr\351lation par noyau pour le suivi d'objets \340 grande vitesse}{chapter.2}% 17
\BOOKMARK [2][-]{subsection.2.4.1}{Pr\351sentation}{section.2.4}% 18
\BOOKMARK [2][-]{subsection.2.4.2}{Analyse}{section.2.4}% 19
\BOOKMARK [1][-]{section.2.5}{R\351capitulatif}{chapter.2}% 20
\BOOKMARK [1][-]{section.2.6}{Conclusion}{chapter.2}% 21
\BOOKMARK [0][]{chapter.3}{Conclusion}{}% 22
\BOOKMARK [1][-]{section.3.1}{Enseignements}{chapter.3}% 23
\BOOKMARK [1][-]{section.3.2}{Perspectives de recherche}{chapter.3}% 24
\BOOKMARK [0][]{appendix.A}{Fiches de lecture}{}% 25
\BOOKMARK [1][-]{section.A.1}{Detecting and Tracking of Multiple People in Video based on Hybrid Detection and Human Anatomy Body Proportion}{appendix.A}% 26
\BOOKMARK [2][-]{subsection.A.1.1}{R\351f\351rence de l'article}{section.A.1}% 27
\BOOKMARK [2][-]{subsection.A.1.2}{Situation des auteurs}{section.A.1}% 28
\BOOKMARK [2][-]{subsection.A.1.3}{Introduction}{section.A.1}% 29
\BOOKMARK [2][-]{subsection.A.1.4}{M\351thode de d\351tection}{section.A.1}% 30
\BOOKMARK [2][-]{subsection.A.1.5}{M\351thode de tra\347age}{section.A.1}% 31
\BOOKMARK [2][-]{subsection.A.1.6}{Conclusion}{section.A.1}% 32
\BOOKMARK [1][-]{section.A.2}{Rapid object detection using a boosted cascade of simple features}{appendix.A}% 33
\BOOKMARK [2][-]{subsection.A.2.1}{R\351f\351rence de l'article}{section.A.2}% 34
\BOOKMARK [2][-]{subsection.A.2.2}{Situation des auteurs}{section.A.2}% 35
\BOOKMARK [2][-]{subsection.A.2.3}{Introduction}{section.A.2}% 36
\BOOKMARK [2][-]{subsection.A.2.4}{D\351finition}{section.A.2}% 37
\BOOKMARK [2][-]{subsection.A.2.5}{M\351thode de d\351tection}{section.A.2}% 38
\BOOKMARK [2][-]{subsection.A.2.6}{Performance}{section.A.2}% 39
\BOOKMARK [2][-]{subsection.A.2.7}{Conclusion}{section.A.2}% 40
\BOOKMARK [1][-]{section.A.3}{You Only Look Once: Unified, Real-Time Object Detection}{appendix.A}% 41
\BOOKMARK [2][-]{subsection.A.3.1}{R\351f\351rence de l'article}{section.A.3}% 42
\BOOKMARK [2][-]{subsection.A.3.2}{Situation des auteurs}{section.A.3}% 43
\BOOKMARK [2][-]{subsection.A.3.3}{Introduction}{section.A.3}% 44
\BOOKMARK [2][-]{subsection.A.3.4}{M\351thode de d\351tection}{section.A.3}% 45
\BOOKMARK [2][-]{subsection.A.3.5}{D\351signe du r\351seau}{section.A.3}% 46
\BOOKMARK [2][-]{subsection.A.3.6}{Performance}{section.A.3}% 47
\BOOKMARK [2][-]{subsection.A.3.7}{Conclusion}{section.A.3}% 48
\BOOKMARK [1][-]{section.A.4}{REAL-TIME MULTIPLE PEOPLE TRACKING WITH DEEPLY LEARNED CANDIDATE SELECTION AND PERSON RE-IDENTIFICATION}{appendix.A}% 49
\BOOKMARK [2][-]{subsection.A.4.1}{R\351f\351rence de l'article}{section.A.4}% 50
\BOOKMARK [2][-]{subsection.A.4.2}{Situation des auteurs}{section.A.4}% 51
\BOOKMARK [2][-]{subsection.A.4.3}{Introduction}{section.A.4}% 52
\BOOKMARK [2][-]{subsection.A.4.4}{M\351thode de d\351tection}{section.A.4}% 53
\BOOKMARK [2][-]{subsection.A.4.5}{D\351signe du r\351seau}{section.A.4}% 54
\BOOKMARK [2][-]{subsection.A.4.6}{M\351thode de tra\347age}{section.A.4}% 55
\BOOKMARK [2][-]{subsection.A.4.7}{M\351thode d'association}{section.A.4}% 56
\BOOKMARK [2][-]{subsection.A.4.8}{M\351thode de comparaison}{section.A.4}% 57
\BOOKMARK [2][-]{subsection.A.4.9}{Association hi\351rarchique des \351tapes de d\351tection et de tra\347age}{section.A.4}% 58
\BOOKMARK [2][-]{subsection.A.4.10}{Performance}{section.A.4}% 59
\BOOKMARK [2][-]{subsection.A.4.11}{Conclusion}{section.A.4}% 60
\BOOKMARK [1][-]{section.A.5}{Bounding Box Embedding for Single Shot Person Instance Segmentation}{appendix.A}% 61
\BOOKMARK [2][-]{subsection.A.5.1}{R\351f\351rence de l'article}{section.A.5}% 62
\BOOKMARK [2][-]{subsection.A.5.2}{Situation des auteurs}{section.A.5}% 63
\BOOKMARK [2][-]{subsection.A.5.3}{Introduction}{section.A.5}% 64
\BOOKMARK [2][-]{subsection.A.5.4}{information}{section.A.5}% 65
\BOOKMARK [2][-]{subsection.A.5.5}{M\351thode de d\351tection}{section.A.5}% 66
\BOOKMARK [2][-]{subsection.A.5.6}{Jeu de donn\351es}{section.A.5}% 67
\BOOKMARK [2][-]{subsection.A.5.7}{Architecture du mod\350le}{section.A.5}% 68
\BOOKMARK [2][-]{subsection.A.5.8}{Conclusion}{section.A.5}% 69
\BOOKMARK [0][]{appendix.B}{Planification}{}% 70
\BOOKMARK [0][]{appendix.C}{Fiches de suivi}{}% 71
\BOOKMARK [0][]{appendix.D}{Auto-contr\364le et auto-\351valuation}{}% 72
